import numpy as np
import rvo2
import json
import os
from pathlib import Path

from collections import defaultdict
import pysocialforce as psf

import matplotlib.animation as animation
import matplotlib.pyplot as plt

from controller import mpc_utils

from sim.environment import Environment
from controller.group import grouping, draw_all_social_spaces

# Imports from sim.metrics
# get_path_length
# get_path_smoothness
# get_motion_smoothness
# get_min_ped_dist
from sim.metrics import *

class Simulator(object):
    # This class maintains the dataset based simulator
    # Each human in the simulator can follow the playback from the dataset
    # or only preserve the start and goals as they first appear/disappear
    # and use ORCA to drive them to the goals.

    def __init__(self, args, case_fpath, logger):
        # case_fpath is the json file path to the test cases
        # please run test_case_generation.py to generate test cases first

        self.output_dir = args.output_dir

        # preload datasets
        self.logger = logger
        self.envs = Environment(args.fps, args.dset_path, logger)
        self.envs.preload_data(args.envs)

        self.dt = args.dt
        self.robot_speed = args.robot_speed
        self.differential = args.differential
        self.collision_radius = args.collision_radius
        self.goal_radius = args.goal_radius
        self.time_horizon = args.time_horizon
        self.use_a_omega = args.use_a_omega

        self.group = args.group
        self.laser = args.laser
        self.pred = args.pred
        self.history = args.history
        self.react = args.react # for if using orca to simulata or use GT trajs
        self.animate = args.animate
        self.record = args.record
        if self.laser:
            self.ped_size = args.ped_size
            self.laser_range = args.laser_range
            self.laser_res = args.laser_res
            self.laser_noise = args.laser_noise

        self.case_id = None

        # for crowd follow debugging
        self.follow_pos = None
        self.follow_vel = None

        self.max_label = None

        self.pred_method = args.pred_method
        self.logger.info("Simulator initialized.")
        self.logger.info("Differential: {}".format(self.differential))
        self.logger.info("Group: {}".format(self.group))
        self.logger.info("Laser: {}".format(self.laser))
        self.logger.info("Pred: {}".format(self.pred))
        self.logger.info("History: {}".format(self.history))
        self.logger.info("React: {}".format(self.react))
        self.logger.info("Animate: {}".format(self.animate))
        self.logger.info("Record: {}".format(self.record))
        self.logger.info("Pred method: {}".format(self.pred_method))

        if self.record:
            self.obs_history = []

        if self.history:
            self.history_steps = args.history_steps
            self.logger.info("History steps: {}".format(self.history_steps))
        if self.pred:
            self.future_steps = args.future_steps
            self.logger.info("Future steps: {}".format(self.future_steps))

        self.done = False

        self.follow_weight = args.follow_weight

        self._load_cases(case_fpath)
        self.reset_cases()

        return

    def _load_cases(self, case_fpath):
        # load the test cases from the json file
        # the test cases are generated by test_case_generation.py
        # the test cases are a list of dictionaries, each dictionary contains the
        # environment name, environment flag, start position, end position, start frame, and time limit

        with open(case_fpath, 'r') as f:
            self.case_list = json.load(f)

        self.case_pt = 0
        return

    def reset_cases(self):
        # shuffle the cases

        self.case_id_list = np.arange(len(self.case_list))
        # np.random.shuffle(self.case_id_list)
        self.case_pt = 0
        return

    def _init_group_params(self):
        # initialize the group parameters

        is_dense_env1 = (self.env_name == "ucy" and self.env_flag == 2)
        is_dense_env2 = (self.env_name == "atc" and self.env_flag == 0)
        if is_dense_env1 or is_dense_env2:
            self.group_params = {
                "size_const": 0.25,
                "pos_threshold": 1.5,
                "th_threshold": 15 / 180.0 * np.pi,
                "spd_threshold": 0.5,
                "spd_ignore": 0.5,  # consider as static if < 0.5 m/s
            }
        else:
            self.group_params = {
                "size_const": 0.35,
                "pos_threshold": 2.0,
                "th_threshold": 30 / 180.0 * np.pi,
                "spd_threshold": 1.0,
                "spd_ignore": 0.5,
            }
        return

    def dataset_history(self, ped_idx):
        # return the position and velocity history of a pedestrian
        # if the pedestrian is not in the dataset, return None

        if ped_idx not in self.pedestrians_idx:
            return None

        pos_history = []
        vel_history = []
        for i in range(self.time - self.history_steps, self.time):
            if (i < 0) or (ped_idx not in self.env.video_pedidx_matrix[i]):
                start_frame = self.env.people_start_frame[ped_idx]
                start_pos = np.array(self.env.people_coords_complete[ped_idx][0])
                start_vel = np.array(self.env.people_velocity_complete[ped_idx][0])
                pos = start_pos - start_vel * (start_frame - i) * self.dt
                vel = start_vel
            else:
                ped_id = self.env.video_pedidx_matrix[i].index(ped_idx)
                pos = self.env.video_position_matrix[i][ped_id]
                vel = self.env.video_velocity_matrix[i][ped_id]
            pos_history.append(pos)
            vel_history.append(vel)

        return pos_history, vel_history

    def _update_from_dataset(self):
        # update the pedestrian attributes from the dataset
        self.pedestrians_pos = self.env.video_position_matrix[self.time]
        self.pedestrians_vel = self.env.video_velocity_matrix[self.time]
        self.pedestrians_idx = self.env.video_pedidx_matrix[self.time]
        self.pedestrians_goal = []
        for ped_idx in self.pedestrians_idx:
            self.pedestrians_goal.append(self.env.people_coords_complete[ped_idx][-1])

        self.pedestrians_pos_history = []
        self.pedestrians_vel_history = []
        if self.history:
            for ped_idx in self.pedestrians_idx:
                pos_history, vel_history = self.dataset_history(ped_idx)
                self.pedestrians_pos_history.append(pos_history)
                self.pedestrians_vel_history.append(vel_history)
        return

    def _ped_to_scans(self, robo_pos, ped_pos, ped_vel):
        # This function simulates laser scan points. Each pedestrian is modeled as a circle.
        # And 'laser' rays come out of the robot in 360 degrees. When a ray first hits
        # a pedestrian circle, we say this is a simulated laser scan point.  The scan point's
        # velocity is the same as the pedestrian's that the ray hits.
        #
        # Inputs: (N is the number of pedestrians)
        # robo_pos (2 element list or tuple) - robot's current position
        # ped_pos (N x 2) - the pedestrians' positions
        # ped_vel (N x 2) - the pedestrians' velocities
        #                   (index must be in same order as ped_pos)
        # Outputs: (M is the number of laser scan points)
        # laser_pos (M x 2) - positions of the simulated laser scans
        # laser_vel (M x 2) - velocities of the simulated laser scans
        #                     (index in same order as laser_pos)

        num_ped = len(ped_pos)

        ang_res = self.laser_res
        det_range = self.laser_range
        noise_limit = self.laser_noise
        ped_radius = self.ped_size
        r_sq = ped_radius ** 2

        laser_pos = []
        laser_vel = []
        ang = 0
        while ang < (2 * np.pi):
            if not (ang % (np.pi / 2) == 0): # or we will get Nan(Inf)
                min_dist = det_range
                laser_x = None
                laser_y = None
                min_idx = None
                for i in range(num_ped):

                    # The math used to check collision with pedestrian circles
                    a = ped_pos[i][0] - robo_pos[0]
                    b = ped_pos[i][1] - robo_pos[1]
                    A = 1 + np.tan(ang) ** 2
                    B = -2 * (a + b * np.tan(ang))
                    C = a ** 2 + b ** 2 - r_sq
                    check_root = round(B ** 2 - 4 * A * C, 12)

                    # If there is a collision
                    if check_root >= 0:
                        x1 = (-B - np.sqrt(check_root)) / (2 * A)
                        y1 = x1 * np.tan(ang)
                        x2 = (-B + np.sqrt(check_root)) / (2 * A)
                        y2 = x2 * np.tan(ang)
                        mag1 = np.sqrt(x1 ** 2 + y1 ** 2)
                        mag2 = np.sqrt(x2 ** 2 + y2 ** 2)
                        # We only want the collision point that is closer to the robot
                        if mag1 < mag2:
                            append_x = x1
                            append_y = y1
                            dist = mag1
                        else:
                            append_x = x2
                            append_y = y2
                            dist = mag2
                        # Inject noise
                        noise = np.random.uniform(-noise_limit, noise_limit)
                        append_x += noise * np.cos(ang)
                        append_y += noise * np.sin(ang)
                        # Check if the same ray has hit a closer pedestrian before
                        if dist < min_dist:
                            min_dist = dist
                            min_idx = i
                            laser_x = append_x + robo_pos[0]
                            laser_y = append_y + robo_pos[1]
                if not (laser_x == None):
                    laser_pos.append([laser_x, laser_y])
                    laser_vel.append([ped_vel[min_idx][0], ped_vel[min_idx][1]])

            ang += ang_res
        return np.array(laser_pos), np.array(laser_vel)

    def _ped_series_to_scans(self, robo_pos, ped_pos_series, ped_vel_series):
        # This function converts a series of pedestrian positions and velocities
        # to a series of laser scans. The pedestrian positions and velocities are
        # assumed to be in the same order as the dataset. The output is a list of
        # laser scans at each time step.
        #
        # Inputs:
        # (N is the number of pedestrians, T is the number of time steps)
        # robo_pos (2 element list or tuple) - robot's current position
        # ped_pos_series (N x T x 2) - the pedestrians' positions at each time step
        # ped_vel_series (N x T x 2) - the pedestrians' velocities at each time step
        # Outputs:
        # (T is the number of time steps, M is the number of laser scan points and can be varied)
        # pos_series (T x M x 2) - positions of the simulated laser scans at each time step
        # vel_series (T x M x 2) - velocities of the simulated laser scans at each time step
        #                          (index in same order as pos_series)

        time_steps = np.shape(ped_pos_series)[1]
        pos_series = []
        vel_series = []
        for i in range(time_steps):
            pos_scan, vel_scan = self._ped_to_scans(robo_pos,
                                            ped_pos_series[:, i, :],
                                            ped_vel_series[:, i, :])
            pos_series.append(pos_scan)
            vel_series.append(vel_scan)
        return pos_series, vel_series

    def _simulate_laser(self):
        # simulate the laser scans
        # if history is True, then simulate the laser scans for the pedestrian history as well

        self.laser_pos, self.laser_vel = self._ped_to_scans(self.robot_pos, self.pedestrians_pos, self.pedestrians_vel)
        self.laser_pos_history = []
        self.laser_vel_history = []
        if self.history:
            # simulate the laser scans for the pedestrian history
            if len(self.laser_pos_history) == 0:
                self.laser_pos_history, self.laser_vel_history = self._ped_series_to_scans(
                        self.robot_pos,
                        np.array(self.pedestrians_pos_history),
                        np.array(self.pedestrians_vel_history))
            else:
                self.laser_pos_history.pop(0)
                self.laser_vel_history.pop(0)
                self.laser_pos_history.append(self.laser_pos)
                self.laser_vel_history.append(self.laser_vel)
        return

    def _group_observations(self):
        # group the observations
        # Note: the history positions and velocities are not grouped
        if len(self.pedestrians_pos) == 0:
            self.group_labels = []
        else:
            self.group_labels = grouping(self.pedestrians_pos, self.pedestrians_vel, self.group_params)
        self.laser_group_labels = []
        if self.laser:
            tmp_group_params = self.group_params.copy()
            tmp_group_params['pos_threshold'] = self.group_params['pos_threshold'] - self.ped_size
            self.laser_group_labels = grouping(self.laser_pos, self.laser_vel, tmp_group_params)
        return

    def _extract_observation(self, observation_dict):
        # Extract information from observation dictionary that is useful to record
        # Useful is defined as needed for evaluation after the trail ends

        record_dict = {}
        record_dict['success'] = observation_dict['success']
        record_dict['num_pedestrians'] = observation_dict['num_pedestrians']
        record_dict['robot_pos'] = observation_dict['robot_pos']
        record_dict['robot_vel'] = observation_dict['robot_vel']
        record_dict['robot_th'] = observation_dict['robot_th']
        record_dict['pedestrians_pos'] = observation_dict['pedestrians_pos']
        record_dict['pedestrians_vel'] = observation_dict['pedestrians_vel']
        record_dict['pedestrians_idx'] = observation_dict['pedestrians_idx']
        record_dict['pedestrians_goal'] = observation_dict['pedestrians_goal']
        if self.laser:
            record_dict['laser_pos'] = observation_dict['laser_pos']
            record_dict['laser_vel'] = observation_dict['laser_vel']
        if self.group:
            record_dict['group_labels'] = observation_dict['group_labels']
            record_dict['laser_group_labels'] = observation_dict['laser_group_labels']
        return record_dict

    def _get_observation_dict(self, success):
        # get the observation dictionary

        observation_dict = {}
        observation_dict['success'] = success
        observation_dict['num_pedestrians'] = self.num_ped
        observation_dict['robot_pos'] = self.robot_pos
        observation_dict['robot_vel'] = self.robot_vel
        observation_dict['robot_th'] = self.robot_th
        observation_dict['robot_goal'] = self.goal_pos
        observation_dict['pedestrians_pos'] = np.array(self.pedestrians_pos)
        observation_dict['pedestrians_vel'] = np.array(self.pedestrians_vel)
        observation_dict['pedestrians_idx'] = np.array(self.pedestrians_idx)
        observation_dict['pedestrians_pos_history'] = np.array(self.pedestrians_pos_history)
        observation_dict['pedestrians_vel_history'] = np.array(self.pedestrians_vel_history)
        observation_dict['pedestrians_goal'] = np.array(self.pedestrians_goal)
        if self.laser:
            observation_dict['laser_pos'] = np.array(self.laser_pos)
            observation_dict['laser_vel'] = np.array(self.laser_vel)
            observation_dict['laser_pos_history'] = self.laser_pos_history
            observation_dict['laser_vel_history'] = self.laser_vel_history
        if self.group:
            observation_dict['group_labels'] = np.array(self.group_labels)
            observation_dict['laser_group_labels'] = np.array(self.laser_group_labels) # empty if laser not enabled

        return observation_dict

    def reset(self, case_id=None):

        self.case_id = case_id

        # reset the environment
        # if case_id is None, then select the next case from the list
        if case_id is None:
            case = self.case_list[self.case_id_list[self.case_pt]]
            self.case_pt += 1
            if self.case_pt >= len(self.case_list):
                self.reset_cases()
        else:
            case = self.case_list[case_id]

        # env is (env_name, env_flag)
        self.env_name = case['env']
        self.env_flag = case['env_flag']

        # clean the folder figs
        if self.animate:
            figs_dir = f"{self.output_dir}/figs/{self.env_name}_{self.env_flag}/case_{self.case_id}"
            if not os.path.exists(figs_dir):
                os.makedirs(figs_dir)
            else:
                for f in os.listdir(figs_dir):
                    os.remove(os.path.join(figs_dir, f))

        self.start_pos = case['start_pos']
        self.goal_pos = case['end_pos']
        # self.start_pos = case['end_pos']
        # self.goal_pos = case['start_pos']


        self.start_frame = case['start_frame']
        self.time_limit = self.start_frame + 3 * case['time_limit']
        # self.time_limit = self.start_frame + 10 * case['time_limit']

        self.env = self.envs.select_env((self.env_name, self.env_flag))
        self._init_group_params()

        self.time = self.start_frame
        self.robot_pos = np.array(self.start_pos)

        # by default, the robot faces the goal
        self.robot_th = np.arctan2(self.goal_pos[1] - self.robot_pos[1], self.goal_pos[0] - self.robot_pos[0]) # robot heading orientation
        self.robot_vel = np.array([0, self.robot_th]) # robot_vel here means robot status (v, theta)
        self.robot_path = np.array([self.robot_pos])

        # For saving the robot path and human path
        self.save_all_traj = []

        # get the pedestrian properties
        self._update_from_dataset()
        self.num_ped = len(self.pedestrians_idx)

        if self.react:
            self.history_idxes = self.pedestrians_idx.copy() # keep track of which pedestrians have showed up

        if self.laser:
            self._simulate_laser()

        if self.group:
            self._group_observations()

        # return the initial observation
        observation_dict = self._get_observation_dict(False)
        if self.record:
            record_dict = self._extract_observation(observation_dict)
            self.obs_history = [record_dict]

        if self.animate:
            self.fig = plt.figure()
            self.image_sequences = []

            frame = self.render()
            self.image_sequences.append(frame)

        self.fail_reason = None

        self.done = False

        return observation_dict

    def _get_pref_velocity(self, pos, goal, spd_limit):
        # get the preferred velocity of a pedestrian
        #
        # pos is the current position
        # goal is the goal position
        # spd_limit is the speed limit

        vel = np.array(goal) - np.array(pos)
        dist = np.linalg.norm(vel)
        if not (dist < self.goal_radius):
            vel = vel / np.linalg.norm(vel) * spd_limit
        else:
            vel = [0, 0]
        return (vel[0], vel[1])

    def rvo_step(self, robo_curr, ped_pos, ped_vel, ped_goals):
        # robo_curr is the current robot position
        # robo_goal is the robot goal position
        # dt is the time step
        # robo_max_v is the robot maximum velocity
        # t_horizon is the time horizon
        # ped_pos is the pedestrian positions
        # ped_vel is the pedestrian velocities
        # ped_goals is the pedestrian goals

        robo_goal = np.array(self.goal_pos)
        dt = self.dt
        t_horizon = self.time_horizon
        robo_max_v = self.robot_speed
        # setting pedestrian max speed to robot max speed
        ped_max_spd = robo_max_v

        # initialize the simulator
        # RVOSimulator(float timeStep, float neighborDist, size_t maxNeighbors, float timeHorizon, float timeHorizonObst, float radius, float maxSpeed)
        sim = rvo2.PyRVOSimulator(dt, 2.5, 10, t_horizon, 2, 0.5, ped_max_spd)

        # add the robot
        robot = sim.addAgent((robo_curr[0], robo_curr[1]))
        sim.setAgentMaxSpeed(robot, robo_max_v)
        sim.setAgentPrefVelocity(robot, self._get_pref_velocity(robo_curr, robo_goal, robo_max_v))

        # add the pedestrians
        num_ped = len(ped_pos)
        ped_list = []
        for i in range(num_ped):
            ped = sim.addAgent((ped_pos[i][0], ped_pos[i][1]))
            ped_spd = np.linalg.norm(np.array(ped_vel[i]))
            sim.setAgentVelocity(ped, (ped_vel[i][0], ped_vel[i][1]))
            sim.setAgentMaxSpeed(ped, max(ped_spd, ped_max_spd))
            sim.setAgentPrefVelocity(ped, self._get_pref_velocity(ped_pos[i], ped_goals[i], ped_max_spd))
            ped_list.append(ped)

        sim.doStep()

        ped_pos_new = np.array([sim.getAgentPosition(ped) for ped in ped_list])
        ped_vel_new = np.array([sim.getAgentVelocity(ped) for ped in ped_list])

        return ped_pos_new, ped_vel_new

    def rvo_step_return_robot(self, robo_curr, ped_pos, ped_vel, ped_goals):
        # robo_curr is the current robot position
        # robo_goal is the robot goal position
        # dt is the time step
        # robo_max_v is the robot maximum velocity
        # t_horizon is the time horizon
        # ped_pos is the pedestrian positions
        # ped_vel is the pedestrian velocities
        # ped_goals is the pedestrian goals

        robo_goal = np.array(self.goal_pos)
        dt = self.dt
        t_horizon = self.time_horizon
        robo_max_v = self.robot_speed
        # setting pedestrian max speed to robot max speed
        ped_max_spd = robo_max_v

        # initialize the simulator
        # RVOSimulator(float timeStep, float neighborDist, size_t maxNeighbors, float timeHorizon, float timeHorizonObst, float radius, float maxSpeed)
        sim = rvo2.PyRVOSimulator(dt, 2.5, 10, t_horizon, 2, 0.5, ped_max_spd)

        # add the robot
        robot = sim.addAgent((robo_curr[0], robo_curr[1]))
        sim.setAgentMaxSpeed(robot, robo_max_v)
        sim.setAgentPrefVelocity(robot, self._get_pref_velocity(robo_curr, robo_goal, robo_max_v))

        # add the pedestrians
        num_ped = len(ped_pos)
        ped_list = []
        for i in range(num_ped):
            ped = sim.addAgent((ped_pos[i][0], ped_pos[i][1]))
            ped_spd = np.linalg.norm(np.array(ped_vel[i]))
            sim.setAgentVelocity(ped, (ped_vel[i][0], ped_vel[i][1]))
            sim.setAgentMaxSpeed(ped, max(ped_spd, ped_max_spd))
            sim.setAgentPrefVelocity(ped, self._get_pref_velocity(ped_pos[i], ped_goals[i], ped_max_spd))
            ped_list.append(ped)

        sim.doStep()

        ped_pos_new = np.array([sim.getAgentPosition(ped) for ped in ped_list])
        ped_vel_new = np.array([sim.getAgentVelocity(ped) for ped in ped_list])

        robot_pos_new = sim.getAgentPosition(robot)
        robot_vel_new = sim.getAgentVelocity(robot)

        return ped_pos_new, ped_vel_new, robot_pos_new, robot_vel_new

    ####### Does not consider robot position affect to human movement simulation
    def rvo_step_norobot(self, ped_pos, ped_vel, ped_goals):
        # dt is the time step
        # robo_max_v is the robot maximum velocity
        # t_horizon is the time horizon
        # ped_pos is the pedestrian positions
        # ped_vel is the pedestrian velocities
        # ped_goals is the pedestrian goals

        dt = self.dt
        t_horizon = self.time_horizon
        robo_max_v = self.robot_speed
        # setting pedestrian max speed to robot max speed
        ped_max_spd = robo_max_v

        # initialize the simulator
        # RVOSimulator(float timeStep, float neighborDist, size_t maxNeighbors, float timeHorizon, float timeHorizonObst, float radius, float maxSpeed)
        sim = rvo2.PyRVOSimulator(dt, 2.5, 10, t_horizon, 2, 0.5, ped_max_spd)

        # add the pedestrians
        num_ped = len(ped_pos)
        ped_list = []
        for i in range(num_ped):
            ped = sim.addAgent((ped_pos[i][0], ped_pos[i][1]))
            ped_spd = np.linalg.norm(np.array(ped_vel[i]))
            sim.setAgentVelocity(ped, (ped_vel[i][0], ped_vel[i][1]))
            sim.setAgentMaxSpeed(ped, max(ped_spd, ped_max_spd))
            sim.setAgentPrefVelocity(ped, self._get_pref_velocity(ped_pos[i], ped_goals[i], ped_max_spd))
            ped_list.append(ped)

        sim.doStep()

        ped_pos_new = np.array([sim.getAgentPosition(ped) for ped in ped_list])
        ped_vel_new = np.array([sim.getAgentVelocity(ped) for ped in ped_list])

        return ped_pos_new, ped_vel_new

    def sfm_step_return_robot(self, old_robot_pos, old_robot_vx_vy, ped_pos, ped_vel, ped_goals, group_labels):
        if len(ped_pos) == 0:  # Check if there are no pedestrians
            ped_pos_new = np.empty((0, 2))  # Shape (0, 2)
            ped_vel_new = np.empty((0, 2))  # Shape (0, 2)
            robot_pos_new = np.array([old_robot_pos[0] + old_robot_vx_vy[0] * self.dt,
                                      old_robot_pos[1] + old_robot_vx_vy[1] * self.dt])
            robot_vel_new = np.array(old_robot_vx_vy)  # (vx, vy)
            return ped_pos_new, ped_vel_new, robot_pos_new, robot_vel_new

        ped_pos = np.array(ped_pos).reshape(-1, 2)  # Shape (num_pedestrians, 2) (px,py)
        ped_vel = np.array(ped_vel).reshape(-1, 2)  # Shape (num_pedestrians, 2) (vx,vy)
        ped_goals = np.array(ped_goals).reshape(-1, 2)  # Shape (num_pedestrians, 2) (gx,gy)
        ped_data = np.column_stack((ped_pos, ped_vel, ped_goals))
        robot_data = np.array([old_robot_pos[0], old_robot_pos[1], old_robot_vx_vy[0], old_robot_vx_vy[1], self.goal_pos[0], self.goal_pos[1]]).reshape(1, -1)

        combined_data = np.vstack((ped_data, robot_data))

        group_dict = defaultdict(list)

        for idx, label in enumerate(group_labels):
            group_dict[label].append(idx)

        if self.max_label is not None:
            group_dict[self.max_label].append(len(combined_data) - 1)

        grouped_indices = list(group_dict.values())
        sfm_config_file = Path(__file__).resolve().parent.parent.joinpath("sfm_config.toml")
        sim = psf.Simulator(combined_data, groups=grouped_indices, obstacles=None, config_file=sfm_config_file)
        sim.step()

        ped_data_all_steps, _ = sim.get_states()
        ped_data_new = ped_data_all_steps[1]
        ped_pos_new = ped_data_new[:-1, :2]
        ped_vel_new = ped_data_new[:-1, 2:4] # (vx, vy)
        robot_pos_new = ped_data_new[-1, :2]
        robot_vel_new = ped_data_new[-1, 2:4]

        return ped_pos_new, ped_vel_new, robot_pos_new, robot_vel_new

    def sfm_step(self, old_robot_pos, old_robot_vx_vy, ped_pos, ped_vel, ped_goals, group_labels):
        if len(ped_pos) == 0:  # Check if there are no pedestrians
            ped_pos_new = np.empty((0, 2))  # Shape (0, 2)
            ped_vel_new = np.empty((0, 2))  # Shape (0, 2)
            return ped_pos_new, ped_vel_new

        ped_pos = np.array(ped_pos).reshape(-1, 2)  # Shape (num_pedestrians, 2) (px,py)
        ped_vel = np.array(ped_vel).reshape(-1, 2)  # Shape (num_pedestrians, 2) (vx,vy)
        ped_goals = np.array(ped_goals).reshape(-1, 2)  # Shape (num_pedestrians, 2) (gx,gy)
        ped_data = np.column_stack((ped_pos, ped_vel, ped_goals))
        robot_data = np.array([old_robot_pos[0], old_robot_pos[1], old_robot_vx_vy[0], old_robot_vx_vy[1], self.goal_pos[0], self.goal_pos[1]]).reshape(1, -1)

        combined_data = np.vstack((ped_data, robot_data))

        group_dict = defaultdict(list)

        for idx, label in enumerate(group_labels):
            group_dict[label].append(idx)

        if self.max_label is not None:
            group_dict[self.max_label].append(len(combined_data) - 1)

        grouped_indices = list(group_dict.values())
        sfm_config_file = Path(__file__).resolve().parent.parent.joinpath("sfm_config.toml")
        sim = psf.Simulator(combined_data, groups=grouped_indices, obstacles=None, config_file=sfm_config_file)
        sim.step()

        ped_data_all_steps, _ = sim.get_states()
        ped_data_new = ped_data_all_steps[1]
        ped_pos_new = ped_data_new[:-1, :2]
        ped_vel_new = ped_data_new[:-1, 2:4] # (vx, vy)

        return ped_pos_new, ped_vel_new

    ####### Does not consider robot position affect to human movement simulation
    def sfm_step_norobot(self, ped_pos, ped_vel, ped_goals, group_labels):
        if len(ped_pos) == 0:  # Check if there are no pedestrians
            ped_pos_new = np.empty((0, 2))  # Shape (0, 2)
            ped_vel_new = np.empty((0, 2))  # Shape (0, 2)
            return ped_pos_new, ped_vel_new

        ped_pos = np.array(ped_pos).reshape(-1, 2)  # Shape (num_pedestrians, 2) (px,py)
        ped_vel = np.array(ped_vel).reshape(-1, 2)  # Shape (num_pedestrians, 2) (vx,vy)
        ped_goals = np.array(ped_goals).reshape(-1, 2)  # Shape (num_pedestrians, 2) (gx,gy)
        ped_data = np.column_stack((ped_pos, ped_vel, ped_goals))

        group_dict = defaultdict(list)

        for idx, label in enumerate(group_labels):
            group_dict[label].append(idx)

        grouped_indices = list(group_dict.values())
        sfm_config_file = Path(__file__).resolve().parent.parent.joinpath("sfm_config.toml")
        sim = psf.Simulator(ped_data, groups=grouped_indices, obstacles=None, config_file=sfm_config_file)
        sim.step()

        ped_data_all_steps, _ = sim.get_states()
        ped_data_new = ped_data_all_steps[1]
        ped_pos_new = ped_data_new[:, :2]
        ped_vel_new = ped_data_new[:, 2:4] # (vx, vy)

        return ped_pos_new, ped_vel_new

    def get_dynamics(self, v, w, th):
        if w == 0 or not self.differential: # get the robot's nice position by following a circular arc
            displacement = np.array([
                v * np.cos(th) * self.dt,
                v * np.sin(th) * self.dt
            ])
        else:
            displacement = np.array([
                v/w * (np.sin(th + w * self.dt) - np.sin(th)),
                -v/w * (np.cos(th + w * self.dt) - np.cos(th))
            ])

        return displacement

    def step(self, action, follow_state=None):

        ##### save the robot path and human path #####
        self.save_all_traj.append({
            "time": self.time,
            "robot_pos": self.robot_pos.copy(),
            "pedestrians_pos": np.array(self.pedestrians_pos).copy(),
            "pedestrians_vel": np.array(self.pedestrians_vel).copy()
        })
        ##############################################

        reward = 0

        if follow_state is not None:
            follow_pos = follow_state[0, :2].copy()
            self.follow_pos = follow_pos
            # follow_vel = follow_state[0, 2:]
            # if np.sum(follow_vel) < 1e6:
            #     self.follow_pos = follow_pos # x, y
            #     self.follow_vel = follow_vel # speed, motion_angle
            # else:
            #     self.follow_pos = None
            #     self.follow_vel = None
        # action is the robot velocity
        # action is a 2D numpy array
        # action[0] is the x velocity, or linear velocity if differential drive
        # action[1] is the y velocity, or angular velocity if differential drive
        # action is in m/s

        if self.done:
            raise ValueError("Environment is done. Please reset.")

        # update time
        self.time += 1

        # update robot position
        old_robot_pos = self.robot_pos.copy()
        old_robot_vx_vy = (self.robot_vel[0] * np.cos(self.robot_th), self.robot_vel[0] * np.sin(self.robot_th))

        if self.use_a_omega: # use a, w as the controller output action
            a, w = action[0], action[1]
            v, th = self.robot_vel[0], self.robot_th
            displacement = self.get_dynamics(v, w, th)
            v += a * self.dt
        else: # use v omega. use v, w as the controller output action
            v, th = action[0], self.robot_th
            w = action[1]
            displacement = self.get_dynamics(v, w, th)
        self.robot_pos = self.robot_pos + displacement
        th = mpc_utils.wrapTo2pi(th + w * self.dt)
        self.robot_vel = np.array([v, th]) # set robot_vel to [v, theta]
        self.robot_th = th

        self.robot_path = np.append(self.robot_path, [self.robot_pos], axis=0)

        # update pedestrian positions
        if self.time > self.env.total_num_frames:
            # no more pedestrian data, so simulator is empty
            self.pedestrians_pos = []
            self.pedestrians_vel = []
            self.pedestrians_idx = []
            self.pedestrians_pos_history = []
            self.pedestrians_vel_history = []
            self.pedestrians_goal = []
        else:
            if self.react:
                # use ORCA to update pedestrian positions
                # tmp_pedestrians_pos, tmp_pedestrians_vel = self.rvo_step(
                #     old_robot_pos, self.pedestrians_pos, self.pedestrians_vel, self.pedestrians_goal)
                # ORCAnoRobot
                # tmp_pedestrians_pos, tmp_pedestrians_vel = self.rvo_step_norobot(
                #     self.pedestrians_pos, self.pedestrians_vel, self.pedestrians_goal)
                # SFM
                tmp_pedestrians_pos, tmp_pedestrians_vel = self.sfm_step(
                    old_robot_pos, old_robot_vx_vy, self.pedestrians_pos, self.pedestrians_vel, self.pedestrians_goal, self.group_labels)
                # SFMnoRobot
                # tmp_pedestrians_pos, tmp_pedestrians_vel = self.sfm_step_norobot(
                #     self.pedestrians_pos, self.pedestrians_vel, self.pedestrians_goal, self.group_labels)
                tmp_pedestrians_idx = self.pedestrians_idx
                if self.history:
                    # update pedestrian history by rolling forward
                    tmp_pedestrians_pos_history = []
                    tmp_pedestrians_vel_history = []
                    for i in range(len(self.pedestrians_pos_history)):
                        tmp_pedestrians_pos_history.append(self.pedestrians_pos_history[i][1:] + self.pedestrians_pos[i])
                        tmp_pedestrians_vel_history.append(self.pedestrians_vel_history[i][1:] + self.pedestrians_vel[i])

                # remove pedestrians that have reached their goals
                new_pedestrians_idx = []
                new_pedestrians_pos = []
                new_pedestrians_vel = []
                new_pedestrians_pos_history = []
                new_pedestrians_vel_history = []
                new_pedestrians_goal = []
                for i in range(len(tmp_pedestrians_pos)):
                    if np.linalg.norm(tmp_pedestrians_pos[i] - self.pedestrians_goal[i]) > self.goal_radius:
                        new_pedestrians_idx.append(tmp_pedestrians_idx[i])
                        new_pedestrians_pos.append(tmp_pedestrians_pos[i])
                        new_pedestrians_vel.append(tmp_pedestrians_vel[i])
                        if self.history:
                            new_pedestrians_pos_history.append(tmp_pedestrians_pos_history[i])
                            new_pedestrians_vel_history.append(tmp_pedestrians_vel_history[i])
                        new_pedestrians_goal.append(self.pedestrians_goal[i])

                # add new pedestrians
                current_pedestrians_idx = self.env.video_pedidx_matrix[self.time]
                for i in range(len(current_pedestrians_idx)):
                    if current_pedestrians_idx[i] not in self.history_idxes:
                        #### if human appear location is too close to robot, dont add ####
                        appear_distance = np.linalg.norm(old_robot_pos - self.env.video_position_matrix[self.time][i])
                        if appear_distance < self.collision_radius + 0.5:
                            continue

                        self.history_idxes.append(current_pedestrians_idx[i])
                        new_pedestrians_idx.append(current_pedestrians_idx[i])
                        new_pedestrians_pos.append(self.env.video_position_matrix[self.time][i])
                        new_pedestrians_vel.append(self.env.video_velocity_matrix[self.time][i])
                        if self.history:
                            pos_history, vel_history = self.dataset_history(current_pedestrians_idx[i])
                            new_pedestrians_pos_history.append(pos_history)
                            new_pedestrians_vel_history.append(vel_history)
                        new_pedestrians_goal.append(self.env.people_coords_complete[current_pedestrians_idx[i]][-1])

                # update the pedestrian properties
                self.pedestrians_idx = new_pedestrians_idx
                self.pedestrians_pos = new_pedestrians_pos
                self.pedestrians_vel = new_pedestrians_vel
                self.pedestrians_pos_history = new_pedestrians_pos_history
                self.pedestrians_vel_history = new_pedestrians_vel_history
                self.pedestrians_goal = new_pedestrians_goal
            else:
                # use dataset to update pedestrian positions
                self._update_from_dataset()

        # TODO: check if success = False is correct. it was success = True but looks not correct.
        success = False
        reach_goal_reward = 0
        self.done = False
        self.num_ped = len(self.pedestrians_idx)

        # check if the episode is done
        if self.time >= self.time_limit:
            self.done = True
            self.fail_reason = "Time"
            self.logger.info("Time limit exceeded. Terminating episode.")
        elif (self.num_ped > 0) and (np.min(np.linalg.norm(self.robot_pos - np.array(self.pedestrians_pos), axis=1)) < self.collision_radius):
            success = False
            self.done = True
            self.fail_reason = "Collision"
            self.logger.info("Collision detected. Terminating episode.")
        elif np.linalg.norm(self.robot_pos - self.goal_pos) < self.goal_radius:
            reach_goal_reward = 1
            success = True
            self.done = True
            self.logger.info("----------------Goal reached----------------")

        if self.laser:
            self._simulate_laser()

        if self.group:
            self._group_observations()

        # update the observation
        observation_dict = self._get_observation_dict(success)
        if self.record:
            record_dict = self._extract_observation(observation_dict)
            self.obs_history.append(record_dict)

        if self.animate:
            frame = self.render()
            self.image_sequences.append(frame)
            ########### save the image to the output directory ##############
            if self.time % 20 == 0:
                tmp_fig = plt.figure()
                tmp_ax = tmp_fig.add_subplot(111)
                self.render_for_save(tmp_ax)
                tmp_fig.savefig(f"{self.output_dir}/figs/{self.env_name}_{self.env_flag}/case_{self.case_id}/{self.time}.png")
                plt.close(tmp_fig)
            #################################################################
            if self.done:
                self._write_video()

        # compute the reward
        ## reward for reaching the goal with range: [-1, 1]
        reach_goal_reward_dense = np.linalg.norm(old_robot_pos - self.goal_pos) - np.linalg.norm(self.robot_pos - self.goal_pos)
        ## reward to getting closer to the goal with range: [0, 1]
        group_matching_score = self.get_group_score(observation_dict)
        group_matching_reward = group_matching_score

        reward += 100 * reach_goal_reward
        reward += 1 * reach_goal_reward_dense
        reward += self.follow_weight * group_matching_reward

        info_dict = {
            "reach_goal_reward": reach_goal_reward,
            "reach_goal_reward_dense": reach_goal_reward_dense,
            "group_matching_reward": group_matching_reward,}

        # return the observation, reward(not used), done, and info
        return observation_dict, reward, self.done, success, self.time, info_dict

    def step_only_orca(self):

        ##### save the robot path and human path #####
        self.save_all_traj.append({
            "time": self.time,
            "robot_pos": self.robot_pos.copy(),
            "pedestrians_pos": np.array(self.pedestrians_pos).copy(),
            "pedestrians_vel": np.array(self.pedestrians_vel).copy()
        })
        ##############################################

        if self.done:
            raise ValueError("Environment is done. Please reset.")

        # update time
        self.time += 1

        # update robot position
        old_robot_pos = self.robot_pos.copy()
        old_robot_vx_vy = (self.robot_vel[0] * np.cos(self.robot_th), self.robot_vel[0] * np.sin(self.robot_th))

        # update pedestrian positions
        if self.time > self.env.total_num_frames:
            # no more pedestrian data, so simulator is empty
            self.pedestrians_pos = []
            self.pedestrians_vel = []
            self.pedestrians_idx = []
            self.pedestrians_pos_history = []
            self.pedestrians_vel_history = []
            self.pedestrians_goal = []
        else:
            if self.react:
                tmp_pedestrians_pos, tmp_pedestrians_vel, new_robot_pos, new_robot_vel = self.sfm_step_return_robot(
                    old_robot_pos, old_robot_vx_vy, self.pedestrians_pos, self.pedestrians_vel, self.pedestrians_goal, self.group_labels)

                # tmp_pedestrians_pos, tmp_pedestrians_vel, new_robot_pos, new_robot_vel = self.rvo_step_return_robot(
                    # old_robot_pos, self.pedestrians_pos, self.pedestrians_vel, self.pedestrians_goal)

                tmp_pedestrians_idx = self.pedestrians_idx
                if self.history:
                    # update pedestrian history by rolling forward
                    tmp_pedestrians_pos_history = []
                    tmp_pedestrians_vel_history = []
                    for i in range(len(self.pedestrians_pos_history)):
                        tmp_pedestrians_pos_history.append(self.pedestrians_pos_history[i][1:] + self.pedestrians_pos[i])
                        tmp_pedestrians_vel_history.append(self.pedestrians_vel_history[i][1:] + self.pedestrians_vel[i])

                # remove pedestrians that have reached their goals
                new_pedestrians_idx = []
                new_pedestrians_pos = []
                new_pedestrians_vel = []
                new_pedestrians_pos_history = []
                new_pedestrians_vel_history = []
                new_pedestrians_goal = []
                for i in range(len(tmp_pedestrians_pos)):
                    if np.linalg.norm(tmp_pedestrians_pos[i] - self.pedestrians_goal[i]) > self.goal_radius:
                        new_pedestrians_idx.append(tmp_pedestrians_idx[i])
                        new_pedestrians_pos.append(tmp_pedestrians_pos[i])
                        new_pedestrians_vel.append(tmp_pedestrians_vel[i])
                        if self.history:
                            new_pedestrians_pos_history.append(tmp_pedestrians_pos_history[i])
                            new_pedestrians_vel_history.append(tmp_pedestrians_vel_history[i])
                        new_pedestrians_goal.append(self.pedestrians_goal[i])

                # add new pedestrians
                current_pedestrians_idx = self.env.video_pedidx_matrix[self.time]
                for i in range(len(current_pedestrians_idx)):
                    if current_pedestrians_idx[i] not in self.history_idxes:
                        #### if human appear location is too close to robot, dont add ####
                        appear_distance = np.linalg.norm(old_robot_pos - self.env.video_position_matrix[self.time][i])
                        if appear_distance < self.collision_radius + 0.5:
                            continue

                        self.history_idxes.append(current_pedestrians_idx[i])
                        new_pedestrians_idx.append(current_pedestrians_idx[i])
                        new_pedestrians_pos.append(self.env.video_position_matrix[self.time][i])
                        new_pedestrians_vel.append(self.env.video_velocity_matrix[self.time][i])
                        if self.history:
                            pos_history, vel_history = self.dataset_history(current_pedestrians_idx[i])
                            new_pedestrians_pos_history.append(pos_history)
                            new_pedestrians_vel_history.append(vel_history)
                        new_pedestrians_goal.append(self.env.people_coords_complete[current_pedestrians_idx[i]][-1])

                # update the pedestrian properties
                self.pedestrians_idx = new_pedestrians_idx
                self.pedestrians_pos = new_pedestrians_pos
                self.pedestrians_vel = new_pedestrians_vel
                self.pedestrians_pos_history = new_pedestrians_pos_history
                self.pedestrians_vel_history = new_pedestrians_vel_history
                self.pedestrians_goal = new_pedestrians_goal
            else:
                # use dataset to update pedestrian positions
                self._update_from_dataset()

        self.robot_pos = new_robot_pos
        new_robot_theta = np.arctan2(new_robot_vel[1], new_robot_vel[0])
        new_robot_speed = np.linalg.norm(new_robot_vel)
        self.robot_vel = np.array([new_robot_speed, new_robot_theta]) # set robot_vel to [v, theta]
        self.robot_th = new_robot_theta

        self.robot_path = np.append(self.robot_path, [self.robot_pos], axis=0)

        # TODO: check if success = False is correct. it was success = True but looks not correct.
        success = False
        reach_goal_reward = 0
        self.done = False
        self.num_ped = len(self.pedestrians_idx)

        # check if the episode is done
        if self.time >= self.time_limit:
            self.done = True
            self.fail_reason = "Time"
            self.logger.info("Time limit exceeded. Terminating episode.")
        elif (self.num_ped > 0) and (np.min(np.linalg.norm(self.robot_pos - np.array(self.pedestrians_pos), axis=1)) < self.collision_radius):
            success = False
            self.done = True
            self.fail_reason = "Collision"
            self.logger.info("Collision detected. Terminating episode.")
        elif np.linalg.norm(self.robot_pos - self.goal_pos) < self.goal_radius:
            reach_goal_reward = 1
            success = True
            self.done = True
            self.logger.info("----------------Goal reached----------------")

        if self.laser:
            self._simulate_laser()

        if self.group:
            self._group_observations()

        # update the observation
        observation_dict = self._get_observation_dict(success)
        if self.record:
            record_dict = self._extract_observation(observation_dict)
            self.obs_history.append(record_dict)

        if self.animate:
            frame = self.render()
            self.image_sequences.append(frame)
            ########### save the image to the output directory ##############
            if self.time % 20 == 0:
                tmp_fig = plt.figure()
                tmp_ax = tmp_fig.add_subplot(111)
                self.render_for_save(tmp_ax)
                tmp_fig.savefig(f"{self.output_dir}/figs/{self.env_name}_{self.env_flag}/case_{self.case_id}/{self.time}.png")
                plt.close(tmp_fig)
            #################################################################
            if self.done:
                self._write_video()

        # compute the reward
        ## reward for reaching the goal with range: [-1, 1]
        reach_goal_reward_dense = np.linalg.norm(old_robot_pos - self.goal_pos) - np.linalg.norm(self.robot_pos - self.goal_pos)
        ## reward to getting closer to the goal with range: [0, 1]
        group_matching_score = self.get_group_score(observation_dict)
        group_matching_reward = group_matching_score

        reward += 100 * reach_goal_reward
        reward += 1 * reach_goal_reward_dense
        reward += self.follow_weight * group_matching_reward

        info_dict = {
            "reach_goal_reward": reach_goal_reward,
            "reach_goal_reward_dense": reach_goal_reward_dense,
            "group_matching_reward": group_matching_reward,}

        # return the observation, reward(not used), done, and info
        return observation_dict, reward, self.done, success, self.time, info_dict

    def get_group_score(self, obs):
        group_data = defaultdict(list)

        for i, label in enumerate(obs["group_labels"]):
            group_data[label].append((obs["pedestrians_pos"][i], obs["pedestrians_vel"][i]))

        group_scores = {}

        if len(group_data) == 0:
            return 0

        for label, members in group_data.items():
            positions = np.array([m[0] for m in members])

            distances = np.linalg.norm(positions - self.robot_pos, axis=1)
            distance_to_group = np.min(distances)

            # if distance_to_group > 3:
            #     group_scores[label] = 0
            #     continue

            velocities = np.array([m[1] for m in members])
            speed = np.linalg.norm(velocities, axis=1)
            motion_angle = np.mod(np.arctan2(velocities[:, 1], velocities[:, 0]), 2 * np.pi)
            avg_speed = np.mean(speed)
            avg_motion_angle = mpc_utils.circmean(motion_angle, np.ones(len(motion_angle)))

            angle_diff = mpc_utils.circdiff(avg_motion_angle, self.robot_vel[1])
            speed_diff = np.abs(avg_speed - self.robot_vel[0])

            sigma_speed = 0.5
            sigma_angle = 15 / 180 * np.pi

            speed_score = np.exp(- (speed_diff / sigma_speed) ** 2)
            angle_score = np.exp(- (angle_diff / sigma_angle) ** 2)

            distance_score = np.exp(- (distance_to_group) ** 2)

            group_scores[label] = speed_score * angle_score * distance_score

        # max_group_score = max(group_scores.values())
        self.max_label, max_group_score = max(group_scores.items(), key=lambda item: item[1])

        if max_group_score == 0:
            self.max_label = None

        return max_group_score


    def evaluate(self, output=False):
        # evaluate the results of the simulation trial
        # can evaluate in the middle of a trial, but a warning will show up

        result_dict = {}

        if not self.record:
            self.logger.error("Recording is not enabled.")
            raise ValueError("Recording is not enabled.")

        if len(self.obs_history) == 0:
            self.logger.warning("No data to evaluate.")
            return result_dict

        if not self.done:
            self.logger.warning("Simulation of this trial is not finished.")

        # Is the trial a success
        result_dict['success'] = self.obs_history[-1]['success']
        result_dict['fail_reason'] = self.fail_reason
        result_dict['navigation_time'] = (self.time - self.start_frame) * self.dt
        result_dict['path_length'] = get_path_length(self.robot_path)
        result_dict['path_smoothness'] = get_path_smoothness(self.robot_path)
        result_dict['motion_smoothness'] = get_motion_smoothness(self.obs_history, self.dt)
        result_dict['min_ped_dist'], result_dict['avg_ped_dist'] = get_min_ped_dist(self.obs_history)
        if self.laser:
            result_dict['min_laser_dist'], result_dict['avg_laser_dist'] = get_min_laser_dist(self.obs_history)

        if output:
            self.logger.info("Success: {}".format(result_dict['success']))
            if not result_dict['success']:
                self.logger.info("Fail reason: {}".format(result_dict['fail_reason']))
            # self.logger.info("Navigation time: {:.2f} s".format(result_dict['navigation_time']))
            # self.logger.info("Path length: {:.2f} m".format(result_dict['path_length']))
            # self.logger.info("Path smoothness: {:.2f}".format(result_dict['path_smoothness']))
            # self.logger.info("Motion smoothness: {:.2f}".format(result_dict['motion_smoothness']))
            # self.logger.info("Min pedestrian distance: {:.2f} m".format(result_dict['min_ped_dist']))
            # self.logger.info("Average pedestrian distance: {:.2f} m".format(result_dict['avg_ped_dist']))
            # if self.laser:
            #     self.logger.info("Min laser distance: {:.2f} m".format(result_dict['min_laser_dist']))
            #     self.logger.info("Average laser distance: {:.2f} m".format(result_dict['avg_laser_dist']))

        return result_dict

    def _write_video(self):
        # write the video of the simulation
        anim = animation.ArtistAnimation(self.fig, self.image_sequences, interval=100, blit=True, repeat_delay=1000)
        ax = plt.gca()
        ax.set_aspect(1)
        Writer = animation.writers['ffmpeg']
        writer = Writer(fps=1/self.dt, metadata=dict(artist='Me'), bitrate=1800)
        #writer = animation.FFMpegWriter(fps = 1/dt)
        video_path = os.path.join(self.output_dir,
                                self.env_name + '_' +
                                str(self.env_flag) + '_' +
                                str(self.case_id) + '_' +
                                str(self.start_frame) + '_' +
                                str(self.time) +
                                '.mp4')
        anim.save(video_path, writer=writer)
        #plt.show()
        self.logger.info("Video saved at {}.".format(video_path))
        return

    def render(self):
        # render the current frame

        curr_frame = []

        # img = plt.imread("localization_grid_white.jpg")
        # img_obj = plt.imshow(img, cmap='gray', vmin=0, vmax=255, extent=[-60, 80, -40, 20])
        # curr_frame.append(img_obj)

        curr_frame.append(plt.title("Time frame: {}".format(self.time)))

        curr_frame.append(plt.scatter(self.start_pos[0], self.start_pos[1], c='g', s=10))
        curr_frame.append(plt.scatter(self.robot_path[:, 0], self.robot_path[:, 1], c='y', s=10))
        curr_frame.append(plt.scatter(self.goal_pos[0], self.goal_pos[1], c='m', s=10))

        # for adding plot follow point, pos and vel in motion_angle, in quiver
        if self.follow_pos is not None:
            curr_frame.append(plt.scatter(self.follow_pos[0], self.follow_pos[1], c='b', s=15))
            # u, v = mpc_utils.pol2cart(self.follow_vel[0], self.follow_vel[1])
            # curr_frame.append(plt.quiver(self.follow_pos[0], self.follow_pos[1], u, v, color='b', scale=1, scale_units='xy', angles='xy'))

        pedestrians_pos = np.array(self.pedestrians_pos)
        pedestrians_vel = np.array(self.pedestrians_vel)

        if self.num_ped > 0:
            curr_frame.append(plt.scatter(pedestrians_pos[:, 0], pedestrians_pos[:, 1], c='r', s=25))
            pedestrian_vel_rho = np.linalg.norm(pedestrians_vel, axis=1)
            pedestrian_vel_theta = np.arctan2(pedestrians_vel[:, 1], pedestrians_vel[:, 0])
            u, v = mpc_utils.pol2cart(pedestrian_vel_rho, pedestrian_vel_theta)
            curr_frame.append(plt.quiver(pedestrians_pos[:, 0], pedestrians_pos[:, 1], u, v, color='r', scale=1, scale_units='xy', angles='xy'))

            if self.laser:
                curr_frame.append(plt.scatter(self.laser_pos[:, 0], self.laser_pos[:, 1], c='b', s=1))
                if self.group:
                    boundaries = draw_all_social_spaces(self.laser_group_labels,
                                                      self.laser_pos,
                                                      self.laser_vel,
                                                      self.group_params['size_const'],
                                                      offset=self.ped_size)
                else:
                    boundaries = []
            else:
                if self.group:
                    boundaries = draw_all_social_spaces(self.group_labels,
                                                      pedestrians_pos,
                                                      pedestrians_vel,
                                                      self.group_params['size_const'],
                                                      offset=0)
                else:
                    boundaries = draw_all_social_spaces(self.pedestrians_idx,
                                                      pedestrians_pos,
                                                      pedestrians_vel,
                                                      self.group_params['size_const'],
                                                      offset=0)
            if len(boundaries) > 0:
                for boundary in boundaries:
                    boundary.append(boundary[0])
                    b = np.array(boundary)
                    group_plt, = plt.plot(b[:, 0], b[:, 1], c='k', linewidth=1)
                    curr_frame.append(group_plt)


        return curr_frame


    def render_for_save(self, ax):
        # render the current frame

        curr_frame = []
        curr_frame.append(ax.scatter(self.start_pos[0], self.start_pos[1], c='g', s=10))
        curr_frame.append(ax.scatter(self.robot_path[:, 0], self.robot_path[:, 1], c='y', s=10))
        curr_frame.append(ax.scatter(self.goal_pos[0], self.goal_pos[1], c='m', s=10))

        curr_frame.append(plt.title("Time frame: {}".format(self.time)))

        # for adding plot follow point, pos and vel in motion_angle, in quiver
        if self.follow_pos is not None and self.follow_vel is not None:
            curr_frame.append(plt.scatter(self.follow_pos[0], self.follow_pos[1], c='b', s=10))
            u, v = mpc_utils.pol2cart(self.follow_vel[0], self.follow_vel[1])
            curr_frame.append(plt.quiver(self.follow_pos[0], self.follow_pos[1], u, v, color='b', scale=1, scale_units='xy', angles='xy'))

        pedestrians_pos = np.array(self.pedestrians_pos)
        pedestrians_vel = np.array(self.pedestrians_vel)

        if self.num_ped > 0:
            curr_frame.append(ax.scatter(pedestrians_pos[:, 0], pedestrians_pos[:, 1], c='r', s=25))
            pedestrian_vel_rho = np.linalg.norm(pedestrians_vel, axis=1)
            pedestrian_vel_theta = np.arctan2(pedestrians_vel[:, 1], pedestrians_vel[:, 0])
            u, v = mpc_utils.pol2cart(pedestrian_vel_rho, pedestrian_vel_theta)
            curr_frame.append(plt.quiver(pedestrians_pos[:, 0], pedestrians_pos[:, 1], u, v, color='r', scale=1, scale_units='xy', angles='xy'))

            if self.laser:
                curr_frame.append(ax.scatter(self.laser_pos[:, 0], self.laser_pos[:, 1], c='b', s=1))
                if self.group:
                    boundaries = draw_all_social_spaces(self.laser_group_labels,
                                                      self.laser_pos,
                                                      self.laser_vel,
                                                      self.group_params['size_const'],
                                                      offset=self.ped_size)
                else:
                    boundaries = []
            else:
                if self.group:
                    boundaries = draw_all_social_spaces(self.group_labels,
                                                      pedestrians_pos,
                                                      pedestrians_vel,
                                                      self.group_params['size_const'],
                                                      offset=0)
                else:
                    boundaries = draw_all_social_spaces(self.pedestrians_idx,
                                                      pedestrians_pos,
                                                      pedestrians_vel,
                                                      self.group_params['size_const'],
                                                      offset=0)
            if len(boundaries) > 0:
                for boundary in boundaries:
                    boundary.append(boundary[0])
                    b = np.array(boundary)
                    group_plt, = ax.plot(b[:, 0], b[:, 1], c='k', linewidth=1)
                    curr_frame.append(group_plt)


        return curr_frame